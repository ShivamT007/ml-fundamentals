{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40abb8e0",
   "metadata": {},
   "source": [
    "# Machine Learning Basics - Regression\n",
    "\n",
    "This notebook provides a practical and theoretical introduction to **Regression analysis**.\n",
    "\n",
    "**Objectives:**\n",
    "- Understand the theory behind regression\n",
    "- Explore different regression techniques\n",
    "- Apply regression to real data\n",
    "- Build interactive visualizations and models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df30c1d",
   "metadata": {},
   "source": [
    "## What is Regression?\n",
    "\n",
    "Regression is a fundamental statistical and machine learning technique used to model and analyze the relationship between a dependent variable (_target_) and one or more independent variables (_features_). It helps us understand how the typical value of the dependent variable changes when any one of the independent variables is varied.\n",
    "\n",
    "**Why is regression important?**\n",
    "- Predict future outcomes (e.g., sales, revenue)\n",
    "- Identify key drivers of business metrics\n",
    "- Support data-driven decision making\n",
    "- Detect trends and patterns\n",
    "\n",
    "**Possible Usecases**\n",
    "Regression can be used for example for:\n",
    "- Forecasting\n",
    "- Resource planning\n",
    "- Performance analysis\n",
    "- Cost prediction\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec07234",
   "metadata": {},
   "source": [
    "## Types of Regression\n",
    "\n",
    "There are several types of regression techniques, each suited for different scenarios:\n",
    "\n",
    "- **Linear Regression:** Models the relationship between two variables by fitting a straight line. Useful for simple, linear relationships.\n",
    "- **Multiple Linear Regression:** Extends linear regression to multiple features.\n",
    "- **Polynomial Regression:** Models non-linear relationships by fitting a polynomial curve.\n",
    "- **Regularized Regression (Ridge, Lasso):** Adds penalties to prevent overfitting and improve generalization.\n",
    "- **Logistic Regression:** Used for predicting categories (e.g., success or failure), not continuous values.\n",
    "\n",
    "In this notebook, we will focus on linear and multiple regression, and demonstrate how to apply them to real data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed303274",
   "metadata": {},
   "source": [
    "# Use Case\n",
    "As a supermarket manager, you want to understand what are the main drivers for your sales. You have noticed that sales have been going well, but in order to increase your branch's revenues even more, you want to target your offers towards the products that drive sales. How can you do that? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2789a582",
   "metadata": {},
   "source": [
    "## The Dataset: Supermarket Sales\n",
    "\n",
    "We will use the [Supermarket Sales dataset](https://www.kaggle.com/datasets/faresashraf1001/supermarket-sales) from Kaggle. This dataset contains sales records for a supermarket, including product, branch, customer, and sales details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8d7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_path = '../../data/SuperMarketAnalysis.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9628b4",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "Let's review the main columns in the dataset:\n",
    "\n",
    "- **Invoice ID:** Unique identifier for each transaction\n",
    "- **Branch:** Branch of the supermarket (A, B, or C)\n",
    "- **City:** City where the branch is located\n",
    "- **Customer type:** Member or Normal\n",
    "- **Gender:** Customer gender\n",
    "- **Product line:** Product category\n",
    "- **Unit price:** Price per product\n",
    "- **Quantity:** Number of products purchased\n",
    "- **Tax 5%:** Tax amount\n",
    "- **Total:** Total price including tax\n",
    "- **Date/Time:** Date and time of purchase\n",
    "- **Payment:** Payment method\n",
    "- **COGS:** Cost of goods sold\n",
    "- **Gross margin percentage:** Gross margin\n",
    "- **Gross income:** Gross income from the sale\n",
    "- **Rating:** Customer rating\n",
    "\n",
    "We will use these features to explore regression techniques.\n",
    "\n",
    "## Frame the Supermarket Sales Problem as a Regression task\n",
    "From the above data dictionary, our **dependent variable** (target) will be `Sales`, as we want to increase revenues. While **independent variables** are inputs that help explain or predict the target. These can be:\n",
    "- Product-related, `Product line`, `Quantity`, `Unit price`\n",
    "- Customer-related, `Gender`, `Customer type`, `City` etc.\n",
    "- Transaction-related, `Date` ,`Time` etc.\n",
    "\n",
    "How are these independent variables useful?\n",
    "<details>\n",
    "        <summary>Answer: Click to show</summary>\n",
    "    Each independent variable helps explain variation of sales in different ways. For example, `Product line` captures different sales patterns across categories, `City` accounts for regional differences in customer demand, store size, or local economy. `Date` and `Time` capture temporal effects, like sales trends over days or peak shopping hours. Together, these features give the regression model multiple perspectives on _why_ a given transaction's total might be higher or lower.\n",
    "</details>\n",
    "\n",
    "\n",
    "The **expected output** would be:\n",
    "1) The prediction of the supermarket sales based on the influence of the independent variable\n",
    "2) An equation that models the relationship between these variables\n",
    "\n",
    "Why would we want an equation?\n",
    "<details>\n",
    "        <summary>Answer: Click to show</summary>\n",
    "    The equation will show the mathematical relationship of the independent variables with respect to the dependent variables. The coefficient will also be useful to determine how much each input influences our target `Sales`.\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100329ca",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "Before diving into modeling, it is important to have first a clear understanding of our dataset (data formats, distributions, missing values, etc.). Let's first check its schema and what are the datatypes that it includes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d40d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for distribution of numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a9c80",
   "metadata": {},
   "source": [
    "From a high level perspective, we notice that we have in total 17 columns and 1000 data points. The Y variable (what we have to predict) is the total Sales (`Sales`), i.e. based on the features captured, how much is the total sales going to be like?\n",
    "\n",
    "Before that though, let's check the distribution of `Total Sales`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a859381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualize distribution of Total sales\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.histplot(df['Sales'], bins=30, kde=True)\n",
    "plt.title('Distribution of Total Sales')\n",
    "plt.xlabel('Total sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca67bc",
   "metadata": {},
   "source": [
    "From this chart we notice the Total distribution of sales. In the x-axis we have the number of total sales, while in the y-axis we have how often these sales have happened. It tells us:\n",
    "- how sales values are spread out (e.g. do most transactions fall in the low-medium range, or are there many high-value purchases?)\n",
    "- presence of skewness or outliers (we notice that the distribution is skewed to the right, meaning that majority of the sales were small purchase and very few large)\n",
    "- customer puchasing behaviour (the shape can help reveal whether spending habits vary widely).\n",
    "\n",
    "Understanding the distribution of the dependent variable is key in the exploratory phase as it helps:\n",
    "- decide if transformations are needed for modeling (e.g. as our sales distribution is skewed to the right, we might consider to take the `log(Sales)` so that large transactions would not dominate the fit)\n",
    "- guide business insights, for example if we know that people make mostly small purchases, then it would also affect how inventory strategy gets optimized "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ae5c17",
   "metadata": {},
   "source": [
    "And now let's do the same by product line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3358d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sales by product line\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.boxplot(x='Product line', y='Sales', data=df)\n",
    "plt.title('Sales by Product Line')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950ff65",
   "metadata": {},
   "source": [
    "We notice that overall they are quite similar with only a couple of outliers in `Sports and travel`, `Foods and beverages`, and `Fashion accessories`. Not only this, but `Fashion accessories` seems to have the least sales in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b94f640",
   "metadata": {},
   "source": [
    "# Linear Regressions\n",
    "\n",
    "The equation looks like this:\n",
    "\n",
    "$$\n",
    "\\text{y} = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\varepsilon\\\n",
    "$$\n",
    "\n",
    "where:\n",
    "- ùë¶: Dependent variable (the target we want to predict, e.g., sales).  \n",
    "- Œ≤0: Intercept (baseline value of ùë¶ when all variables are 0).  \n",
    "- ùõΩ1,ùõΩ2,‚Ä¶,ùõΩùëù: Coefficients (show how much ùë¶ changes when each x increases by 1, holding others constant).  \n",
    "- x1‚Äã,x2‚Äã,‚Ä¶,xp: Independent variables (features/variables).  \n",
    "- Œµ: Error term (captures noise and variation not explained by the model).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e0ee2",
   "metadata": {},
   "source": [
    "## Simple Linear Regression\n",
    "\n",
    "Simple linear regression models the relationship between two variables by fitting a straight line. In business, it can be used to predict sales based on a **single feature**, such as unit price or quantity.\n",
    "\n",
    "**Example use cases:**\n",
    "- Predicting sales from advertising spend\n",
    "- Estimating revenue from number of customers\n",
    "\n",
    "Let's build a simple linear regression model to predict total `Sales` based on `Unit price`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1f0c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Linear Regression: Predict Total from Unit price\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Prepare data\n",
    "X = df[['Unit price']].values\n",
    "y = df['Sales'].values\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Interactive plot\n",
    "@widgets.interact(unit_price=widgets.FloatSlider(min=float(df['Unit price'].min()), max=float(df['Unit price'].max()), step=0.5, value=float(df['Unit price'].mean()), description='Unit price:'))\n",
    "def plot_regression(unit_price):\n",
    "    pred = model.predict(np.array([[unit_price]]))[0]\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=df['Unit price'], y=df['Sales'], mode='markers', name='Data'))\n",
    "    fig.add_trace(go.Scatter(x=df['Unit price'], y=y_pred, mode='lines', name='Regression Line'))\n",
    "    fig.add_trace(go.Scatter(x=[unit_price], y=[pred], mode='markers', marker=dict(size=12, color='red'), name='Prediction'))\n",
    "    fig.update_layout(title='Simple Linear Regression: Total vs Unit price', xaxis_title='Unit price', yaxis_title='Total')\n",
    "    fig.show()\n",
    "    print(f'Predicted Total for Unit price {unit_price:.2f}: {pred:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e12cba",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Multiple linear regression models the relationship between a target variable and **two or more** features. This allows us to capture more complex relationships and improve prediction accuracy.\n",
    "\n",
    "**Business relevance:**\n",
    "- Predicting sales using multiple factors (e.g., unit price, quantity, branch, product line)\n",
    "- Understanding the impact of different variables on business outcomes\n",
    "\n",
    "Let's build a multiple regression model to predict total `Sales` using several features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bae40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression: Predict Total from multiple features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Select features (excluding target and identifiers)\n",
    "features = ['Unit price', 'Quantity', 'Branch', 'Product line', 'Gender', 'Customer type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43d6767",
   "metadata": {},
   "source": [
    "Before moving on to the modeling phase, a necessary step is needed: Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fb1357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "df_encoded = pd.get_dummies(df[features], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03742c8",
   "metadata": {},
   "source": [
    "\n",
    "Encoding categorical variables is necessary because regression models require **numerical input**. However, real-world data often include categorical variables (e.g., `Product line`). These must be converted into numerical format because:\n",
    "- Models cannot understand text or categories natively\n",
    "- Numeric reoresebtatuibs allow models to learn relationship between features and their target (`Sales`)\n",
    "\n",
    "There are several types of encoding methods depending on the type and number of categories, some are: \n",
    "\n",
    "1) **One hot encoding**\n",
    "- Creates a new binary column for each category \n",
    "- Best for nomincal (unordered) categories \n",
    "\n",
    "\n",
    "```\n",
    "Color: [\"red\", \"green\", \"blue\"]\n",
    "‚Üí One-hot encoded:\n",
    "Red | Green | Blue\n",
    " 1  |   0   |  0\n",
    " 0  |   1   |  0\n",
    " 0  |   0   |  1\n",
    "```\n",
    "\n",
    "2) **Label encoding**\n",
    "- Assigns a unique integer to each category.\n",
    "- Can mislead models into thinking there's an ordinal relationship.\n",
    "- Often used for tree-based models, or truly ordinal variables.\n",
    "\n",
    "```\n",
    "Color: [\"red\", \"green\", \"blue\"]\n",
    "‚Üí Label encoded: [2, 1, 0]\n",
    "```\n",
    "\n",
    "\n",
    "3) **Ordinal encoding**\n",
    "/ Smilar to label encoding but used when categories have a natural oder (e.g. small < medium < large)\n",
    "\n",
    "```\n",
    "Size: [\"small\", \"medium\", \"large\"]\n",
    "‚Üí Ordinal encoded: [0, 1, 2]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f45496",
   "metadata": {},
   "source": [
    "In our use case we used `pd.get_dummies()` which is a form of one-hot encoding. It in fact converted our categorical variables into binary indicator variables - one column for each category, with `1` indicating presence and `0` absence.\n",
    "\n",
    "Before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ae00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Branch'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f7d23",
   "metadata": {},
   "source": [
    "After one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f278a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded[['Branch_Cairo', 'Branch_Giza']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656cc22b",
   "metadata": {},
   "source": [
    "We use one-hot encoding in linear regression when categorical variables are present, because the model can only handle numeric inputs. \n",
    "\n",
    "Instead of assigning arbitrary numbers (which would wrongly imply an order), one-hot encoding creates binary indicator variables that let the model learn a separate coefficient for each category without introducing false ordinal relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25933388",
   "metadata": {},
   "source": [
    "Let's go back to our modeling now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccc9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_encoded\n",
    "y = df['Sales']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model_multi = LinearRegression()\n",
    "model_multi.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_multi.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R^2 Score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e39bd1",
   "metadata": {},
   "source": [
    "- Mean Squared Error (MSE) measures the average of the square of the errors, i.e. how far your model's predictions are from the actual values (the lower the better). In our case, on average our predictions are off by about square root of MSE units (80 units).\n",
    "- R squared tells you the proportion of variance in the target, i.e. the % of the bariance in the target that is explained by the model (the closer to 1 the better). In our case, our model can explain the data quite well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbcfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compare performances on training and test sets\n",
    "y_train_pred = model_multi.predict(X_train)\n",
    "y_test_pred = model_multi.predict(X_test)\n",
    "\n",
    "# Mean Squared Error\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train MSE:\", mse_train)\n",
    "print(\"Test MSE:\", mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2dbd3e",
   "metadata": {},
   "source": [
    "As you can see, our MSE can be improved. Both MSE are high, meaning that our model is most likely _underfitting_ and we should consider more flexible models, such as polynomial features, non-linear models, or improving our features with feature engineering.\n",
    "\n",
    "\n",
    "What is underfitting?\n",
    "<details>\n",
    "        <summary>Answer: Click to show</summary>\n",
    "    Underfitting happens when a model is too simple to capture the underlying patterns in the data. It fails to learn enough from the training set, leading to high error in both training and test data\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb9bcf",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "In this notebook, you have learned:\n",
    "- The theory and business relevance of regression\n",
    "- How to apply simple and multiple linear regression\n",
    "- How to use regularization to improve model performance\n",
    "- How to interactively explore regression models using real data\n",
    "\n",
    "**Next steps:**\n",
    "- Try different features and targets. Feel free to edit the current notebook with additional features and test out how adding more features influences the model prediction!\n",
    "- Explore non-linear regression and tree-based models (more info in [./05_advanced_regression.ipynb](./05_advanced_regression.ipynb))\n",
    "\n",
    "For more advanced topics, consider learning about:\n",
    "- Model evaluation and selection\n",
    "- Cross-validation\n",
    "- Feature engineering\n",
    "- Machine learning pipelines\n",
    "\n",
    "Thank you for following this regression tutorial!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regression_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
